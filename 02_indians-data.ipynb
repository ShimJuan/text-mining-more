{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"02_indians-data.ipynb","provenance":[]}},"cells":[{"cell_type":"code","metadata":{"id":"nscg3asc_iyF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":222},"executionInfo":{"status":"error","timestamp":1594003261218,"user_tz":-540,"elapsed":1010,"user":{"displayName":"심좐","photoUrl":"","userId":"17197281327989967181"}},"outputId":"82539a8d-6944-4106-dcb4-77de2a2dc0a6"},"source":["# 딥러닝을 구동하는 데 필요한 케라스 함수를 불러옵니다.\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","\n","# 필요한 라이브러리를 불러옵니다.\n","import numpy as np\n","import tensorflow as tf\n","import pandas as pd\n","\n","# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.\n","numpy.random.seed(3)\n","tf.random.set_seed(3)"],"execution_count":2,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-4502449bfa9a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# 실행할 때마다 같은 결과를 출력하기 위해 설정하는 부분입니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'numpy' is not defined"]}]},{"cell_type":"markdown","metadata":{"id":"hgk7KTPq_mii","colab_type":"text"},"source":["txt test"]},{"cell_type":"code","metadata":{"id":"YlpOWDri_iyI","colab_type":"code","colab":{}},"source":["data = np.loadtxt('dataset/pima-indians-diabetes.csv',delimiter=',')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iKh6KpJr_iyK","colab_type":"code","colab":{}},"source":["x = data[:,0:8]\n","y = data[:,8]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMV2gCYc_iyM","colab_type":"code","colab":{},"outputId":"66489233-f71c-472c-a203-f67a60fbe3ff"},"source":["x"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[  6.   , 148.   ,  72.   , ...,  33.6  ,   0.627,  50.   ],\n","       [  1.   ,  85.   ,  66.   , ...,  26.6  ,   0.351,  31.   ],\n","       [  8.   , 183.   ,  64.   , ...,  23.3  ,   0.672,  32.   ],\n","       ...,\n","       [  5.   , 121.   ,  72.   , ...,  26.2  ,   0.245,  30.   ],\n","       [  1.   , 126.   ,  60.   , ...,  30.1  ,   0.349,  47.   ],\n","       [  1.   ,  93.   ,  70.   , ...,  30.4  ,   0.315,  23.   ]])"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"66PE3OZP_iyP","colab_type":"code","colab":{},"outputId":"db7cbd95-4619-48d8-9742-73fb75552b69"},"source":["y"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 1., 1., 1.,\n","       1., 0., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 1., 0., 0.,\n","       0., 0., 0., 1., 1., 1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0.,\n","       0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 1., 0.,\n","       0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n","       0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 0.,\n","       0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 1., 1., 1., 1., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0.,\n","       1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n","       1., 1., 1., 0., 0., 1., 1., 0., 1., 0., 1., 1., 1., 0., 0., 0., 0.,\n","       0., 0., 1., 1., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1.,\n","       1., 0., 0., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 1., 1.,\n","       1., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       1., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 0., 1., 1., 0.,\n","       0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1., 1., 0., 0., 1., 0.,\n","       0., 0., 1., 1., 1., 0., 0., 1., 0., 1., 0., 1., 1., 0., 1., 0., 0.,\n","       1., 0., 1., 1., 0., 0., 1., 0., 1., 0., 0., 1., 0., 1., 0., 1., 1.,\n","       1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 1., 1., 1.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n","       1., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 1., 1., 0., 0., 0.,\n","       0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n","       1., 0., 0., 1., 0., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 0.,\n","       1., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 0., 1.,\n","       1., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0.,\n","       0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 1.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n","       1., 0., 0., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n","       1., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n","       1., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n","       0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 1., 1., 1., 0.,\n","       0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       1., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 0.,\n","       1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0., 1., 0., 0., 0., 0., 1.,\n","       1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","       0., 1., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0.,\n","       1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 1.,\n","       1., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 1., 0.,\n","       0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 1., 0., 1., 0., 1., 1.,\n","       0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0., 1., 0.,\n","       0., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n","       1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 1., 0., 0., 1., 0.,\n","       1., 1., 1., 0., 0., 1., 1., 1., 0., 1., 0., 1., 0., 1., 0., 0., 0.,\n","       0., 1., 0.])"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"T8nBWlLD_iyR","colab_type":"code","colab":{}},"source":["# 딥러닝 구조를 결정 \n","model = Sequential()\n","# 모델을 설정하고 실행하는 부분 \n","model.add(Dense(30, input_dim=8, activation='relu'))\n","model.add(Dense(1,activation='sigmoid'))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"keSk9X9k_iyT","colab_type":"code","colab":{},"outputId":"6a086369-f375-46d5-f94c-f4d40ee294fd"},"source":["model.compile(loss='mean_squared_error',optimizer='adam',metrics=['accuracy'])\n","model.fit(x,y,epochs=100,batch_size=10)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/100\n","77/77 [==============================] - 0s 857us/step - loss: 0.3493 - accuracy: 0.6497\n","Epoch 2/100\n","77/77 [==============================] - 0s 845us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 3/100\n","77/77 [==============================] - 0s 779us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 4/100\n","77/77 [==============================] - 0s 727us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 5/100\n","77/77 [==============================] - 0s 857us/step - loss: 0.3511 - accuracy: 0.6484\n","Epoch 6/100\n","77/77 [==============================] - 0s 740us/step - loss: 0.3489 - accuracy: 0.6497\n","Epoch 7/100\n","77/77 [==============================] - 0s 766us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 8/100\n","77/77 [==============================] - 0s 701us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 9/100\n","77/77 [==============================] - 0s 770us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 10/100\n","77/77 [==============================] - 0s 753us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 11/100\n","77/77 [==============================] - 0s 727us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 12/100\n","77/77 [==============================] - 0s 740us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 13/100\n","77/77 [==============================] - 0s 805us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 14/100\n","77/77 [==============================] - 0s 909us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 15/100\n","77/77 [==============================] - 0s 831us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 16/100\n","77/77 [==============================] - 0s 791us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 17/100\n","77/77 [==============================] - 0s 910us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 18/100\n","77/77 [==============================] - 0s 922us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 19/100\n","77/77 [==============================] - 0s 857us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 20/100\n","77/77 [==============================] - 0s 831us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 21/100\n","77/77 [==============================] - 0s 779us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 22/100\n","77/77 [==============================] - 0s 779us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 23/100\n","77/77 [==============================] - 0s 909us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 24/100\n","77/77 [==============================] - 0s 817us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 25/100\n","77/77 [==============================] - 0s 857us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 26/100\n","77/77 [==============================] - 0s 779us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 27/100\n","77/77 [==============================] - 0s 701us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 28/100\n","77/77 [==============================] - 0s 792us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 29/100\n","77/77 [==============================] - 0s 805us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 30/100\n","77/77 [==============================] - 0s 903us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 31/100\n","77/77 [==============================] - 0s 844us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 32/100\n","77/77 [==============================] - 0s 936us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 33/100\n","77/77 [==============================] - 0s 922us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 34/100\n","77/77 [==============================] - 0s 922us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 35/100\n","77/77 [==============================] - 0s 805us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 36/100\n","77/77 [==============================] - 0s 766us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 37/100\n","77/77 [==============================] - 0s 805us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 38/100\n","77/77 [==============================] - 0s 779us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 39/100\n","77/77 [==============================] - 0s 961us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 40/100\n","77/77 [==============================] - 0s 961us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 41/100\n","77/77 [==============================] - 0s 844us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 42/100\n","77/77 [==============================] - 0s 792us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 43/100\n","77/77 [==============================] - 0s 779us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 44/100\n","77/77 [==============================] - 0s 844us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 45/100\n","77/77 [==============================] - 0s 909us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 46/100\n","77/77 [==============================] - 0s 792us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 47/100\n","77/77 [==============================] - 0s 831us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 48/100\n","77/77 [==============================] - 0s 792us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 49/100\n","77/77 [==============================] - 0s 890us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 50/100\n","77/77 [==============================] - 0s 714us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 51/100\n","77/77 [==============================] - 0s 870us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 52/100\n","77/77 [==============================] - 0s 779us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 53/100\n","77/77 [==============================] - 0s 844us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 54/100\n","77/77 [==============================] - 0s 844us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 55/100\n","77/77 [==============================] - 0s 636us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 56/100\n","77/77 [==============================] - 0s 688us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 57/100\n","77/77 [==============================] - 0s 844us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 58/100\n","77/77 [==============================] - 0s 766us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 59/100\n","77/77 [==============================] - 0s 766us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 60/100\n","77/77 [==============================] - 0s 701us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 61/100\n","77/77 [==============================] - 0s 741us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 62/100\n","77/77 [==============================] - 0s 623us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 63/100\n","77/77 [==============================] - 0s 779us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 64/100\n","77/77 [==============================] - 0s 701us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 65/100\n","77/77 [==============================] - 0s 701us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 66/100\n","77/77 [==============================] - 0s 754us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 67/100\n","77/77 [==============================] - 0s 714us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 68/100\n","77/77 [==============================] - 0s 649us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 69/100\n","77/77 [==============================] - 0s 740us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 70/100\n","77/77 [==============================] - 0s 676us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 71/100\n","77/77 [==============================] - 0s 779us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 72/100\n","77/77 [==============================] - 0s 675us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 73/100\n","77/77 [==============================] - 0s 691us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 74/100\n","77/77 [==============================] - 0s 688us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 75/100\n","77/77 [==============================] - 0s 753us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 76/100\n","77/77 [==============================] - 0s 690us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 77/100\n","77/77 [==============================] - 0s 739us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 78/100\n","77/77 [==============================] - 0s 663us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 79/100\n","77/77 [==============================] - 0s 677us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 80/100\n","77/77 [==============================] - 0s 636us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 81/100\n","77/77 [==============================] - 0s 714us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 82/100\n","77/77 [==============================] - 0s 688us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 83/100\n","77/77 [==============================] - 0s 870us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 84/100\n","77/77 [==============================] - 0s 728us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 85/100\n","77/77 [==============================] - 0s 675us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 86/100\n","77/77 [==============================] - 0s 792us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 87/100\n","77/77 [==============================] - 0s 753us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 88/100\n","77/77 [==============================] - 0s 753us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 89/100\n","77/77 [==============================] - 0s 740us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 90/100\n","77/77 [==============================] - 0s 766us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 91/100\n","77/77 [==============================] - 0s 701us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 92/100\n","77/77 [==============================] - 0s 662us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 93/100\n","77/77 [==============================] - 0s 831us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 94/100\n","77/77 [==============================] - 0s 688us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 95/100\n","77/77 [==============================] - 0s 702us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 96/100\n","77/77 [==============================] - 0s 666us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 97/100\n","77/77 [==============================] - 0s 714us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 98/100\n","77/77 [==============================] - 0s 701us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 99/100\n","77/77 [==============================] - 0s 689us/step - loss: 0.3490 - accuracy: 0.6510\n","Epoch 100/100\n","77/77 [==============================] - 0s 714us/step - loss: 0.3490 - accuracy: 0.6510\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x1f275993f88>"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"y-WWyKM8_iyW","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}